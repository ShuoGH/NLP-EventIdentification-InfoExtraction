{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract information about breaking news events\n",
    "The input of this task is the outpur of previous task.\n",
    "\n",
    "Given the label of breaking news, to extract the information from the news. Therefore, the task here is basically a NER task, to get the entity like the `person` or `location`.\n",
    "\n",
    "In this task, the `ArticleTitle` and `ArticleDescription` both are going to be used.\n",
    "\n",
    "Pipeline:\n",
    "- Load data set and prepare the data \n",
    "- NER (named entity recognition) work\n",
    "- Get results and output into file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input is the output of last task\n",
    "df=pd.read_csv(\"output/news_dataset_labeled_task1.csv\")\n",
    "df_fill=df.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>ArticleURL</th>\n",
       "      <th>ArticleTitle</th>\n",
       "      <th>ArticleDescription</th>\n",
       "      <th>ArticlePublishedTime</th>\n",
       "      <th>EventId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5cd7ed707ddacd3b2b3b549e</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-england-suffolk-...</td>\n",
       "      <td>Lowestoft sea wall fall cyclist rescued by friend</td>\n",
       "      <td>Coastguards praise the boy's friend for his ac...</td>\n",
       "      <td>1557653530</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5cd7e83beb96a44751294217</td>\n",
       "      <td>https://www.highsnobiety.com/p/met-gala-best-c...</td>\n",
       "      <td>The Met Gala &amp; ‘Game of Thrones’ Feature in Th...</td>\n",
       "      <td>Once again, our ever-sarcastic readership have...</td>\n",
       "      <td>1557653563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5cd7e99a8e662d1e4435cb3d</td>\n",
       "      <td>https://www.mirror.co.uk/news/uk-news/boy-dies...</td>\n",
       "      <td>Boy dies on prom day after allergic reaction t...</td>\n",
       "      <td>Joe Dale's family have spoken out about losing...</td>\n",
       "      <td>1557653574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5cd7f6dd7ddacd3b2b3b56ab</td>\n",
       "      <td>https://www.independent.co.uk/voices/paddy-jac...</td>\n",
       "      <td>Paddy Jackson’s return to Rugby is yet more pr...</td>\n",
       "      <td>He may have been found not guilty of rape last...</td>\n",
       "      <td>1557653588</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5cd7e89c8e662d1e4435cb13</td>\n",
       "      <td>https://www.standard.co.uk/showbiz/celebrity-n...</td>\n",
       "      <td>BAFTA TV Awards 2019: Stars prepare for glitzy...</td>\n",
       "      <td>Stars are preparing for Sunday night s TV Baft...</td>\n",
       "      <td>1557653610</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ArticleId  \\\n",
       "0  5cd7ed707ddacd3b2b3b549e   \n",
       "1  5cd7e83beb96a44751294217   \n",
       "2  5cd7e99a8e662d1e4435cb3d   \n",
       "3  5cd7f6dd7ddacd3b2b3b56ab   \n",
       "4  5cd7e89c8e662d1e4435cb13   \n",
       "\n",
       "                                          ArticleURL  \\\n",
       "0  https://www.bbc.co.uk/news/uk-england-suffolk-...   \n",
       "1  https://www.highsnobiety.com/p/met-gala-best-c...   \n",
       "2  https://www.mirror.co.uk/news/uk-news/boy-dies...   \n",
       "3  https://www.independent.co.uk/voices/paddy-jac...   \n",
       "4  https://www.standard.co.uk/showbiz/celebrity-n...   \n",
       "\n",
       "                                        ArticleTitle  \\\n",
       "0  Lowestoft sea wall fall cyclist rescued by friend   \n",
       "1  The Met Gala & ‘Game of Thrones’ Feature in Th...   \n",
       "2  Boy dies on prom day after allergic reaction t...   \n",
       "3  Paddy Jackson’s return to Rugby is yet more pr...   \n",
       "4  BAFTA TV Awards 2019: Stars prepare for glitzy...   \n",
       "\n",
       "                                  ArticleDescription  ArticlePublishedTime  \\\n",
       "0  Coastguards praise the boy's friend for his ac...            1557653530   \n",
       "1  Once again, our ever-sarcastic readership have...            1557653563   \n",
       "2  Joe Dale's family have spoken out about losing...            1557653574   \n",
       "3  He may have been found not guilty of rape last...            1557653588   \n",
       "4  Stars are preparing for Sunday night s TV Baft...            1557653610   \n",
       "\n",
       "   EventId  \n",
       "0       -1  \n",
       "1        0  \n",
       "2        1  \n",
       "3       -1  \n",
       "4       -1  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fill.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>ArticleURL</th>\n",
       "      <th>ArticleTitle</th>\n",
       "      <th>ArticleDescription</th>\n",
       "      <th>ArticlePublishedTime</th>\n",
       "      <th>EventId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5cd7e99a8e662d1e4435cb3d</td>\n",
       "      <td>https://www.mirror.co.uk/news/uk-news/boy-dies...</td>\n",
       "      <td>Boy dies on prom day after allergic reaction t...</td>\n",
       "      <td>Joe Dale's family have spoken out about losing...</td>\n",
       "      <td>1557653574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5cd7fa408e662d1e4435d112</td>\n",
       "      <td>https://www.independent.co.uk/news/uk/home-new...</td>\n",
       "      <td>Boy collapses and dies after suffering allergi...</td>\n",
       "      <td>Parents speak out over 'heart-wrenching' loss ...</td>\n",
       "      <td>1557654432</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ArticleId  \\\n",
       "2   5cd7e99a8e662d1e4435cb3d   \n",
       "47  5cd7fa408e662d1e4435d112   \n",
       "\n",
       "                                           ArticleURL  \\\n",
       "2   https://www.mirror.co.uk/news/uk-news/boy-dies...   \n",
       "47  https://www.independent.co.uk/news/uk/home-new...   \n",
       "\n",
       "                                         ArticleTitle  \\\n",
       "2   Boy dies on prom day after allergic reaction t...   \n",
       "47  Boy collapses and dies after suffering allergi...   \n",
       "\n",
       "                                   ArticleDescription  ArticlePublishedTime  \\\n",
       "2   Joe Dale's family have spoken out about losing...            1557653574   \n",
       "47  Parents speak out over 'heart-wrenching' loss ...            1557654432   \n",
       "\n",
       "    EventId  \n",
       "2         1  \n",
       "47        1  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fill[df_fill['EventId']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the later work, the data labelled as `-1` will not be modelled. Only the labelled event `0,1, ...` will be extracted and the results will be written into the csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To extract the information from the articles\n",
    "\n",
    "The task is basically a NER (named entity recognition) problem. \n",
    "\n",
    "`spacy` is used again in this part, loading the pre-trained model.\n",
    "\n",
    "The information expected to be extracted:\n",
    "- NewsTimePeriod\n",
    "- RelatedDate\n",
    "- Person\n",
    "- EventLocation\n",
    "- EventSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") # load the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:04<00:00,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER finished in this corpus.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "event_ents_list = []\n",
    "\n",
    "for i in tqdm(range(df_fill['EventId'].max()+1)):\n",
    "    event_ents = []\n",
    "    df_event = df_fill[df_fill['EventId'] == i]\n",
    "    for index, content in df_event.iterrows():\n",
    "        doc_title = nlp(content['ArticleTitle'])\n",
    "        doc_description = nlp(content['ArticleDescription'])\n",
    "\n",
    "        for ent in doc_title.ents:\n",
    "            event_ents.append((ent.text, ent.label_))\n",
    "        for ent in doc_description.ents:\n",
    "            event_ents.append((ent.text, ent.label_))\n",
    "    event_ents_list.append(event_ents)\n",
    "print(\"NER finished in this corpus.\")\n",
    "#     print(event_ents)\n",
    "\n",
    "#     df_event_ents=df_event_ents.append(pd.Series(event_ents),ignore_index=True)\n",
    "#     df_event_ents.iloc[i,'EventEnts']=event_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_entity_frequency(ent_label, ents_list):\n",
    "    '''\n",
    "    Count the frequency of words in a certain entity and sort to get the order.\n",
    "    args:\n",
    "        ents_list: the list of entities extracted by the nlp model\n",
    "    return:\n",
    "        keys list: the order is descending, sorted by the value. The most frequent word is the `out[0]`\n",
    "    '''\n",
    "    text_ent_frequency={}\n",
    "    for (text,label) in ents_list:\n",
    "        if label==ent_label:\n",
    "            text_ent_frequency[text]= text_ent_frequency.get(text,0)+1\n",
    "    \n",
    "    return sorted(text_ent_frequency,key=text_ent_frequency.get,reverse=True)\n",
    "\n",
    "\n",
    "def extract_information(df_event, event_id, ents_list):\n",
    "    '''\n",
    "    Basically, use the frequency of entities to decide the information.\n",
    "    For each kind of entity, we see the word with the highest frequency as the key information\n",
    "    \n",
    "    the `EventSummary` hasn't been realized in this part.\n",
    "    '''\n",
    "    info = pd.Series(\n",
    "        index=['EventId', 'NewsNumber', 'NewsTimeLength', 'RelatedDate', 'Person', 'EventLocation', 'EventSummary'])\n",
    "\n",
    "    info['EventId'] = event_id\n",
    "    df_event['ArticlePublishedTime'] = pd.to_datetime(df_event['ArticlePublishedTime'], unit='s')\n",
    "    info['NewsNumber'] = df_event.shape[0]\n",
    "    info['NewsTimeLength'] = df_event['ArticlePublishedTime'].max()-df_event['ArticlePublishedTime'].min()\n",
    "    try:\n",
    "        info['RelatedDate']=count_entity_frequency('DATE',ents_list)[0]\n",
    "        info['Person']=count_entity_frequency('PERSON',ents_list)[0]\n",
    "        info['EventLocation']=count_entity_ferquency('LOC',ents_list)[0]+', '+count_entity_ferquency('GPE',ents_list)[0]\n",
    "        info['EventSummary']=''\n",
    "    except IndexError:\n",
    "        pass\n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.Series(\n",
    "        index=['EventId', 'NewsNumber', 'NewsTimeLength', 'RelatedDate', 'Person', 'EventLocation', 'EventSummary'])\n",
    "info['EventId']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33 [00:00<?, ?it/s]/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████| 33/33 [00:04<00:00,  7.12it/s]\n"
     ]
    }
   ],
   "source": [
    "df_information = pd.DataFrame(columns=[\n",
    "                              'EventId', 'NewsNumber', 'NewsTimeLength', 'RelatedDate', 'Person', 'EventLocation', 'EventSummary'])\n",
    "# df_event_ents=pd.DataFrame(columns=['EventEnts'])\n",
    "for i in tqdm(range(df_fill['EventId'].max()+1)):\n",
    "    info=extract_information(df_fill[df_fill['EventId']==i],i,event_ents_list[i])\n",
    "#     print(info)\n",
    "    df_information=df_information.append(info,ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>NewsNumber</th>\n",
       "      <th>NewsTimeLength</th>\n",
       "      <th>RelatedDate</th>\n",
       "      <th>Person</th>\n",
       "      <th>EventLocation</th>\n",
       "      <th>EventSummary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>03:27:17</td>\n",
       "      <td>A decade</td>\n",
       "      <td>Lyft Earnings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>00:14:18</td>\n",
       "      <td>prom day</td>\n",
       "      <td>Joe Dale's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>04:21:07</td>\n",
       "      <td>today</td>\n",
       "      <td>Kick-off</td>\n",
       "      <td>Cross River, Manchester City</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>03:59:22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>01:08:00</td>\n",
       "      <td>today</td>\n",
       "      <td>Sport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventId  NewsNumber NewsTimeLength RelatedDate         Person  \\\n",
       "0      0.0         2.0       03:27:17    A decade  Lyft Earnings   \n",
       "1      1.0         2.0       00:14:18    prom day     Joe Dale's   \n",
       "2      2.0       157.0       04:21:07       today       Kick-off   \n",
       "3      3.0         2.0       03:59:22         NaN            NaN   \n",
       "4      4.0         2.0       01:08:00       today          Sport   \n",
       "\n",
       "                  EventLocation EventSummary  \n",
       "0                           NaN          NaN  \n",
       "1                           NaN          NaN  \n",
       "2  Cross River, Manchester City               \n",
       "3                           NaN          NaN  \n",
       "4                           NaN          NaN  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_information.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_information.to_csv(\"output/extracted_information_task2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this part,\n",
    "\n",
    "NER, in this part, I use `spacy` again to realize it. The model used is already pre-trained. I just need to call the APIs to get the output.\n",
    "\n",
    "Article Summary, I didn't realize the article summary part. I haven't found a good exercise to get the text summary. I know the idea of using the extracted entities to get the relation, then generate the summary. But I don't know how to realize it. I still need to do more reading on this part.\n",
    "\n",
    "\n",
    "(to be continue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
